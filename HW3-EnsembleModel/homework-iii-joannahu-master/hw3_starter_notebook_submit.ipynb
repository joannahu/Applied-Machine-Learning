{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI:  qh2174\n",
    "* Name: Qiong Hu\n",
    "\n",
    "### Team Member 2 [optional]:\n",
    "* UNI:  qc2217\n",
    "* Name: Qi Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict,GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures,OneHotEncoder,LabelEncoder,Imputer,FunctionTransformer,scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,VotingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We get X_complete, Y_complete from data.csv, and get holdout_data from holdout.csv.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(filename1, filename2):\n",
    "    X_complete = pd.read_csv(filename1, usecols=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "    Y_complete = pd.read_csv(filename1, usecols=[20])\n",
    "    X_holdout = pd.read_csv(filename2)\n",
    "    return X_complete, Y_complete,X_holdout\n",
    "X_complete,Y_complete, X_holdout = load_data('data.csv','holdout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "In the 'subscriebed' column in Y_complete, we replace 'no' with 0, and replace 'yes' with 1. \n",
    "\n",
    "We remove the 'Duration' column in X_complete and holdout_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    y[y==\"yes\"] = 1\n",
    "    y[y==\"no\"] = 0\n",
    "    y = np.asarray(y)\n",
    "    y_list = []\n",
    "    for item in y:\n",
    "        y_list.append(item[0])\n",
    "    y = np.asarray(y_list)\n",
    "    return y\n",
    "\n",
    "def feature_selection(filename, is_train):\n",
    "    if is_train: #training data\n",
    "        category_index = [1, 2, 3, 4, 5, 6, 7, 8, 9, 14]\n",
    "        continuous_index = [0, 11, 12, 13, 15, 16, 17, 18, 19]\n",
    "    else: #testing data\n",
    "        holdout_id = np.array(pd.read_csv(filename))[:,0]\n",
    "        holdout_id = holdout_id.astype(int)\n",
    "        category_index = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15]\n",
    "        continuous_index = [1, 12, 13, 14, 16, 17, 18, 19, 20]\n",
    "        \n",
    "    data_category = pd.read_csv(filename, dtype=np.str, usecols=category_index)\n",
    "    data_continuous = pd.read_csv(filename, dtype=np.float32, usecols=continuous_index)\n",
    "    x = np.append(data_category, data_continuous, axis=1)\n",
    "    if is_train: #training data (with y)\n",
    "        return x\n",
    "    else: #testing data (without y)\n",
    "        return x,holdout_id\n",
    "    \n",
    "\n",
    "X = feature_selection('data.csv',True)\n",
    "holdout_data, holdout_id = feature_selection('holdout.csv',False)\n",
    "Y = transform_y(Y_complete)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process we do \n",
    "\n",
    "We scale the continuous variables.\n",
    "\n",
    "We use LabelEncoder and OneHotEncoder to transform categorical data into numeric data in X and holdout_data. \n",
    "\n",
    "Then we split X into X_train, y_train, X_test, y_test.  \n",
    "\n",
    "Since the data is imbalanced, we tried to oversample and undersample the data. And we find that oversampling has a better performance. So we comment the undersampling process.\n",
    "\n",
    "And we choose the features with top 90% f score. \n",
    "\n",
    "The model we choose are: Logistic Regression, Knn, Nearest Centroids, Gaussian Naive Bayes, SVM models. We use GridSearchCV with different number of cv to in each model find the best parameters.\n",
    "\n",
    "#### Model select\n",
    "Logistic Regression roc score is about 0.8018908687. Knn roc score is about 0.7513665713. Nearest Centroid roc score is about 0.7432849. Gaussian Naive Bayes roc score is about 0.774527286. SVM roc score is about 0.77278532.\n",
    "\n",
    "Logistic Regression has the best performance. So we will choose it in later ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(x, y, x_holdout):\n",
    "    \n",
    "    # Scale \n",
    "    select_categorical = x[:, 0:10]\n",
    "    select_continuous = x[:, 10:]\n",
    "    select_categorical_holdout = x_holdout[:, 0:10]\n",
    "    select_continuous_holdout = x_holdout[:, 10:]\n",
    "    select_continuous = scale(select_continuous)\n",
    "    select_continuous_holdout = scale(select_continuous_holdout)\n",
    "    x = np.append(select_categorical, select_continuous, axis=1)\n",
    "    x_holdout = np.append(select_categorical_holdout, select_continuous_holdout, axis=1)\n",
    "              \n",
    "    # LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for i in range(10):\n",
    "        le.fit(x[:, i])\n",
    "        x[:, i] = le.transform(x[:, i])\n",
    "        x_holdout[:, i] = le.transform(x_holdout[:, i])\n",
    "\n",
    "    # OneHotEncoder\n",
    "    encoder = OneHotEncoder(categorical_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                            sparse=False)  # input must be numeric (not string)\n",
    "    encoder.fit(x)\n",
    "    x = encoder.transform(x)\n",
    "    x_holdout = encoder.transform(x_holdout)\n",
    "    \n",
    "    # Split data into train data and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 56)\n",
    "\n",
    "    #oversample dataset\n",
    "    ros = RandomOverSampler()\n",
    "    X_train, y_train = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    '''#undersamle dataset\n",
    "    rus = RandomUnderSampler()\n",
    "    X_train, y_train = rus.fit_sample(X_train, y_train)\n",
    "    '''\n",
    "    \n",
    "    # feature selection\n",
    "    select=SelectPercentile(score_func=f_regression,percentile=90)\n",
    "    select.fit(X_train,y_train)\n",
    "    X_train=select.transform(X_train)\n",
    "    X_test=select.transform(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, x_holdout, x\n",
    "\n",
    "X_train, y_train, X_test, y_test,X_holdout, X = prepare_data(X, Y, holdout_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression model\n",
    "def logistic_regression_classifier(X_train,y_train, X_test, y_test):\n",
    "    params = {'C':[0.1, 0.5, 1, 5, 10, 100]}\n",
    "    #oversample: clf = GridSearchCV(LogisticRegression(class_weight='balanced'), params, cv=10, n_jobs=-1).fit(X_train, y_train)\n",
    "    clf = GridSearchCV(LogisticRegression(), params, cv=10, n_jobs=-1).fit(X_train, y_train)\n",
    "    y_predict = clf.predict_proba(X_test)[:,1]\n",
    "    lr_score= roc_auc_score(y_test, y_predict)\n",
    "    return lr_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#knn model\n",
    "def knn_classifier(X_train,y_train, X_test, y_test):\n",
    "    k = np.arange(20)+1\n",
    "    parameters = {'n_neighbors': k}\n",
    "    knn = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn,parameters,cv=10)\n",
    "    clf.fit(X_train,y_train)\n",
    "    knn_score = roc_auc_score(y_test, knn.predict_proba(X_test)[:,1])\n",
    "    return knn_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nearest Centroids\n",
    "def nc_classifier(X_train,y_train, X_test, y_test):\n",
    "    nc = NearestCentroid()\n",
    "    nc.fit(X_train,y_train)\n",
    "    nc_score = roc_auc_score(y_test, nc.predict(X_test))\n",
    "    return nc_score, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes model\n",
    "def naive_bayes_classifier(X_train,y_train, X_test, y_test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    nb_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return nb_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "def svm_classifier(X_train,y_train, X_test, y_test):\n",
    "    parameters = {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.05, 0.1, 0.5, 1]}\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc,parameters,cv=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    svm_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return svm_score, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our try\n",
    "Before we get our highest score, since the data has some 'unknown' value, we processed the data by imputing the data('most_frequenct'). But the roc score is not that high. So we give up these processing steps. \n",
    "\n",
    "#### The following is the code we tried but didn't choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def select_feature(filename, is_train):\n",
    "\n",
    "    if is_train: #training data\n",
    "        category_index = [1, 2, 3, 4, 5, 6, 7, 8, 9, 14]\n",
    "        continuous_index = [0, 11, 13, 15, 16, 17, 18, 19]\n",
    "    else: #testing data\n",
    "        holdout_id = np.array(pd.read_csv(filename))[:,0]\n",
    "        holdout_id = holdout_id.astype(int)\n",
    "        category_index = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15]\n",
    "        continuous_index = [1, 12, 13, 14, 16, 17, 18, 19, 20]\n",
    "\n",
    "    #for imputing\n",
    "    missing = {\"job\": ['unknown'], \"marital_status\": ['unknown'], \"education\": ['unknown'],\n",
    "               'credit_default': ['unknown'], 'housing': ['unknown'], 'loan': ['unknown']}\n",
    "    \n",
    "    data_category = pd.read_csv(filename, dtype=np.str, usecols=category_index, na_values=missing)\n",
    "    data_continuous = pd.read_csv(filename, dtype=np.float32, usecols=continuous_index, na_values=missing)\n",
    "    x = np.append(data_category, data_continuous, axis=1)\n",
    "    if is_train: #training data (with y)\n",
    "        y = pd.read_csv('data.csv', usecols=['subscribed'])\n",
    "        return x,y\n",
    "    else: #testing data (without y)\n",
    "        return x,holdout_id\n",
    "\n",
    "\n",
    "def data_processing(x, x_holdout):\n",
    "    # Scale \n",
    "    select_categorical = x[:, 0:10]\n",
    "    select_continuous = x[:, 10:]\n",
    "    select_categorical_holdout = x_holdout[:, 0:10]\n",
    "    select_continuous_holdout = x_holdout[:, 10:]\n",
    "    select_continuous = scale(select_continuous)\n",
    "    select_continuous_holdout = scale(select_continuous_holdout)\n",
    "    x = np.append(select_categorical, select_continuous, axis=1)\n",
    "    x_holdout = np.append(select_categorical_holdout, select_continuous_holdout, axis=1)\n",
    "    \n",
    "    #for imputing\n",
    "    x = pd.DataFrame(x)\n",
    "    x = x.fillna('null')\n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    # LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for i in range(10):\n",
    "        le.fit(x[:, i])\n",
    "        x[:, i] = le.transform(x[:, i])\n",
    "        \n",
    "        #imputing: fill Nan\n",
    "        l = list(le.inverse_transform(x[:,i].tolist()))\n",
    "        indices = [j for j, k in enumerate(l) if k == \"null\"]\n",
    "        for j in indices:\n",
    "            x[j][i] = np.nan\n",
    "    \n",
    "    # Impute x\n",
    "    imp = Imputer(strategy='most_frequent').fit(x)\n",
    "    x = imp.transform(x)\n",
    "\n",
    "    # OneHotEncoder\n",
    "    encoder = OneHotEncoder(categorical_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                            sparse=False)  # input must be numeric (not string)\n",
    "    encoder.fit(x)\n",
    "    x = encoder.transform(x)\n",
    "    return x, x_holdout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process\n",
    "The data processing (feature engineering, feature selection) is the same with that of Step2 ModelSet1.\n",
    "\n",
    "#### Model select\n",
    "\n",
    "We choose Decision Tree, GradientBoosting, Random Forest, AdaBoosting and ExtraTreesClassifier models in ModelSet2.\n",
    "\n",
    "Decision Tree roc score is about 0.7633922753. GradientBoosting roc score is about 0.8008535437.Random Forest roc score is about 0.8058265199. AdaBoosting roc score is about 0.791998019343. ExtraTreesClassifier roc score is about 0.7811898194. \n",
    "\n",
    "So we will choose GradientBoosting, Random Forest, AdaBoosting, ExtraTreesClassifier in the later ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "def decision_tree(X_train,y_train, X_test, y_test):\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=3, random_state=0)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_score = roc_auc_score(y_test, dt.predict_proba(X_test)[:,1])\n",
    "    return dt_score, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GradientBoosting Model\n",
    "def gradient_boosting(X_train,y_train, X_test, y_test):\n",
    "    params = {'n_estimators':range(30,100,5)}\n",
    "    GB = GradientBoostingClassifier(learning_rate=0.08,max_depth=8,min_samples_split=500, \n",
    "                                    min_samples_leaf=50,max_features='sqrt', random_state=20)\n",
    "    clf = GridSearchCV(GB, params, cv=3, n_jobs=-1).fit(X_train, y_train)\n",
    "    GB_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return GB_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "def random_forest(X_train,y_train, X_test, y_test):\n",
    "    params = {'n_estimators':range(50,250,50)} #'max_depth':[3,6,9]\n",
    "    #RF = RandomForestClassifier(n_estimators=150, n_jobs=-1,class_weight='balanced')\n",
    "    RF = RandomForestClassifier(max_depth = 6, n_jobs=-1, random_state=0)\n",
    "    clf = GridSearchCV(RF, params, cv=5).fit(X_train, y_train)\n",
    "    rf_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return rf_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#AdaBoosting Model\n",
    "def ada_boosting(X_train,y_train, X_test, y_test):\n",
    "    params = {'learning_rate':[0.01, 0.05, 0.1, 0.5, 1], 'n_estimators': range(50,300,50) }\n",
    "    Ada = AdaBoostClassifier(random_state=0)\n",
    "    clf = GridSearchCV(Ada, params, cv=3).fit(X_train, y_train)\n",
    "    ada_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return ada_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier\n",
    "def extra_tree(X_train,y_train, X_test, y_test):\n",
    "    params = { 'n_estimators': range(50,250,50) }\n",
    "    extra = ExtraTreesClassifier(random_state=0, n_estimators=300)\n",
    "    clf = GridSearchCV(extra, params, cv=3).fit(X_train, y_train)\n",
    "    et_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return ada_score, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here.\n",
    "\n",
    "#### We created three ensemble classifiers. Finally we choose the last ensemble: blending_classifier.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voting classifier\n",
    "we ensembled three classifiers (Logistic Regression, Random Forest, Gradient Boosting) with the weight of 10%, 30%, 60% respectively. The roc score is about 0.798033751247. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Voting classifier\n",
    "def voting_classifier(X_train,y_train, X_test, y_test):\n",
    "    voting = VotingClassifier([('LogisticRegression',LogisticRegression(C=1)),\n",
    "                          ('RandomForest', RandomForestClassifier(max_depth=6, n_estimators=150, random_state=0)),\n",
    "                          ('GradientBoosting', GradientBoostingClassifier(learning_rate=0.08, max_depth=8,n_estimators=85,random_state=20))\n",
    "                          ],\n",
    "                         voting='soft', weights=[1,3,6])\n",
    "    voting.fit(X_train,y_train)\n",
    "    lr,tree,gb = voting.estimators_\n",
    "    score = roc_auc_score(y_test, voting.predict_proba(X_test)[:,1])\n",
    "    return score, voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poor man stacking\n",
    "We use voting with three classifiers(Logistic Regression, Random Forest, Gradient Boosting). Then use Logistic Regression on the voting results.  The roc score is about 0.70 before we do resampling.\n",
    "\n",
    "#### After we resample it, we get a better performance.\n",
    "When we use undersampling, the roc score improves to 0.75. When we use oversampling, the roc score jumps to 0.962469072977(which is weird but we don't know why). So we finally choose oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poor_man(X_train, y_train):\n",
    "    voting = VotingClassifier([('LogisticRegression',LogisticRegression(C=1)),\n",
    "                          ('RandomForest', RandomForestClassifier(max_depth=6, n_estimators=150, random_state=0)),\n",
    "                          ('GradientBoosting', GradientBoostingClassifier(learning_rate=0.08,\n",
    "                                                                          max_depth=8,n_estimators=85,random_state=0))\n",
    "                          ], voting='soft', weights=[1,3,6])\n",
    "    reshaper = FunctionTransformer(lambda X_: np.rollaxis(X_, 1).reshape(-1,6)[:, 1::2], validate=False)\n",
    "    stacking = make_pipeline(voting, reshaper, LogisticRegression(C=100))\n",
    "    stacking.fit(X_train, y_train)\n",
    "    return np.mean(cross_val_score(stacking, X_train, y_train, cv=5, scoring='roc_auc')), stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking_classifier\n",
    "\n",
    "Firstly, we use KNeighborsClassifier, RandomForestClassifier. Then a meta-classifier \"LogisticRegression\" is used to do fitting based on the outputs. Before we do resampling, the roc score is about 0.71, which is not a good performance. \n",
    "\n",
    "#### After we resample it, we get a better performance.\n",
    "When we use undersampling, the roc score improves to 0.76. When we use oversampling, the roc score jumps to 0.96(which is weird but we don't know why). So we finally choose oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stacking classifier\n",
    "def stacking_classifier(X,Y, X_holdout,holdout_id):\n",
    "    #oversample dataset\n",
    "    ros = RandomOverSampler()\n",
    "    X_oversample, y_oversample = ros.fit_sample(X, Y)\n",
    "    \n",
    "    clf1 = AdaBoostClassifier(random_state=0,n_estimators=150,learning_rate=0.1)\n",
    "    clf2 = RandomForestClassifier(random_state=0,n_estimators=150)\n",
    "    clf3 = GaussianNB()\n",
    "    lr = LogisticRegression()\n",
    "    sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "    print('3-fold cross validation:\\n')\n",
    "\n",
    "    for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                          ['Ada Boost', \n",
    "                           'Random Forest', \n",
    "                           'Naive Bayes',\n",
    "                           'StackingClassifier']):\n",
    "        \n",
    "        scores = cross_val_score(clf, X_oversample, y_oversample, cv=3, scoring='accuracy')\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "        scores = cross_val_score(clf, X_oversample, y_oversample, cv=3, scoring='roc_auc')\n",
    "        print(\"roc_auc: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    #y_holdout = sclf.predict_proba(X_holdout)[:, 1]\n",
    "    #y_holdout = cross_val_predict(sclf, X_holdout, cv=3)\n",
    "    #save_csv_numpy(holdout_id, y_holdout)\n",
    "    return scores\n",
    "\n",
    "#stacking_classifier(X,Y,X_holdout,holdout_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending classifier ensemble\n",
    "In this ensemble, we stack 5 base models(RandomForests, ExtraTrees, GradientBoosting) in StratifiedKfold with the meta-classifier GradientBoosting.\n",
    "\n",
    "We use two For-loop. In the first For-loop, there are 5 different classifiers. In the second For-loop, we use StratifiedKfold to split the data into 5 train-test folds. In each split, we create predictions for X_test and X_holdout. When creating predictions for the X_holdout, we take an average of the out-of-fold predictors.\n",
    "\n",
    "Finally, the meta-classifier GradientBoosting is used to do fitting based on the outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blending_classifier(X,Y, X_holdout,holdout_id):\n",
    "    clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy', random_state=0),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini', random_state=0),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy', random_state=0),\n",
    "            GradientBoostingClassifier(learning_rate=0.08, subsample=0.8, max_depth=8, n_estimators=85, random_state=20)]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5) #5 folders\n",
    "\n",
    "    dataset_blend_train = np.zeros((X.shape[0], len(clfs))) #to save X_test prediction\n",
    "    dataset_blend_test = np.zeros((X_holdout.shape[0], len(clfs)))#to save X_holdout prediction\n",
    "\n",
    "    for j, clf in enumerate(clfs):\n",
    "        dataset_blend_test_j = np.zeros((X_holdout.shape[0], 5))\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = Y[train_index], Y[test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            dataset_blend_train[test_index, j] = clf.predict_proba(X_test)[:, 1]\n",
    "            dataset_blend_test_j[:, i] = clf.predict_proba(X_holdout)[:, 1]\n",
    "        dataset_blend_test[:, j] = dataset_blend_test_j.mean(1) # get average of dataset_blend_test_j\n",
    "\n",
    "\n",
    "    clf1 = GradientBoostingClassifier()\n",
    "    clf1.fit(dataset_blend_train, Y)\n",
    "    y_submission = clf1.predict_proba(dataset_blend_test)[:, 1]\n",
    "    y_scores = clf1.predict_proba(dataset_blend_train)[:, 1]\n",
    "    y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "    #save_csv_numpy(holdout_id, y_submission)\n",
    "    return roc_auc_score(Y, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_csv_numpy(holdout_id, y_submission):\n",
    "    tmp = np.vstack([holdout_id, y_submission]).T\n",
    "    np.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f', header='ID,subscribed', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_csv(X_holdout, holdout_id, clf):\n",
    "    holdout_predict = clf.predict_proba(X_holdout)\n",
    "    holdout = np.zeros(shape=(len(holdout_id),2))\n",
    "    holdout_id = pd.DataFrame(holdout_id)\n",
    "    holdout_predict = pd.DataFrame(holdout_predict)\n",
    "\n",
    "    holdout = pd.concat([holdout_id, holdout_predict[1]], axis = 1)\n",
    "    holdout.columns = [\"ID\",\"subscribed\"]\n",
    "    holdout.to_csv('holdout_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803163021884\n",
      "0.806829058849\n"
     ]
    }
   ],
   "source": [
    "def test(X_train,y_train, X_test, y_test, X_holdout, X, Y, holdout_id):  \n",
    "    #get score from logistic regression classifier\n",
    "    score, clf = logistic_regression_classifier(X_train,y_train, X_test, y_test)\n",
    "    #check score\n",
    "    print (score)\n",
    "    assert score > 0.79\n",
    "    \n",
    "    #get score from gradient boosting classifier\n",
    "    score,clf = gradient_boosting(X_train,y_train, X_test, y_test)\n",
    "    #check score\n",
    "    print (score)\n",
    "    assert score > 0.79\n",
    "    \n",
    "    #get score from random forest classifier\n",
    "    score,clf = random_forest(X_train,y_train, X_test, y_test)\n",
    "    #check score\n",
    "    print (score)\n",
    "    assert score > 0.79\n",
    "    \n",
    "    #get score from voting classifier\n",
    "    score,clf = voting_classifier(X_train,y_train, X_test, y_test)\n",
    "    #check score\n",
    "    print (score)\n",
    "    assert score > 0.79\n",
    "    \n",
    "    #get score from blending classifier\n",
    "    score = blending_classifier(X,Y, X_holdout, holdout_id)\n",
    "    #check score\n",
    "    print (score)\n",
    "    assert score > 0.79\n",
    "    \n",
    "test(X_train,y_train, X_test, y_test, X_holdout, X, Y, holdout_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
